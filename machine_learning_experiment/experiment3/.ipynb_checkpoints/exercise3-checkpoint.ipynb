{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f68bae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from collections import Counter\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51a79d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = pd.read_csv('./SMSSpamCollection', sep='\\t', header=None)\n",
    "data = sms.loc[:,1]\n",
    "target = sms.loc[:,0]\n",
    "data = data.values.tolist()\n",
    "target = target.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c20e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textParse(bigString):  # 输入big string，输出word list\n",
    "    import re\n",
    "    listOfTokens = re.split('\\W', bigString)\n",
    "    return [tok.lower() for tok in listOfTokens if len(tok) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d38e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_and_split(data_path:str, val_rate:float):\n",
    "    \"\"\"\n",
    "    加载数据集并划分训练集和验证集\n",
    "    :param data_path: 数据集路径\n",
    "    :param val_rate: 验证集比例\n",
    "    :return: 训练集列表，验证集列表，训练集标签列表，验证集标签列表\n",
    "    \"\"\"\n",
    "    sms = pd.read_csv(data_path, sep='\\t', header=None)\n",
    "    data_lines = sms.loc[:,1].values.tolist()\n",
    "    label_list = sms.loc[:,0].values.tolist()\n",
    "    data_list = []\n",
    "    for data_line in data_lines:\n",
    "        data_line = textParse(data_line)\n",
    "        data_list.append(data_line)\n",
    "    train_data, val_data, train_label, val_label = train_test_split(data_list, label_list, test_size=val_rate, \n",
    "                                                                        random_state=random.randint(0,1000),shuffle=True)\n",
    "    return train_data,val_data, train_label,val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f68e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_label, val_label = load_data_and_split('./SMSSpamCollection',0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a66c8a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCategorySum(labels):\n",
    "    \"\"\"\n",
    "    获取每个类别以及其数量\n",
    "    \"\"\"\n",
    "    countCategory = Counter(labels)\n",
    "    return list(countCategory.keys()),list(countCategory.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56292035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrods2Vec(dataSet):\n",
    "    \"\"\"\n",
    "    计算数据集中各个词出现的概率\n",
    "    \"\"\"\n",
    "    words2VecList = {}\n",
    "    for data_line in dataSet:\n",
    "        for data in data_line:\n",
    "            if data in words2VecList:\n",
    "                words2VecList[data] += 1\n",
    "            else:\n",
    "                words2VecList[data] = 1\n",
    "    wordsSum = np.sum(list(words2VecList.values()))\n",
    "    for key, value in words2VecList.items():\n",
    "        words2VecList[key] = value / wordsSum\n",
    "    return words2VecList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e05e90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2VecWithLable(dataSet, labels):\n",
    "    \"\"\"\n",
    "    计算每个标签类别下各个词出现的概率\n",
    "    \"\"\"\n",
    "    lableSet = set(labels)\n",
    "    word2VecWithLableList = {}\n",
    "    labelCount = Counter(labels)\n",
    "    for lable in lableSet:\n",
    "        subSet = []\n",
    "        for i in range(len(labels)):\n",
    "            if lable == labels[i]:\n",
    "                subSet.append(dataSet[i])\n",
    "        word2VecWithLableList[lable] = wrods2Vec(subSet)\n",
    "    return labelCount,word2VecWithLableList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bfef5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNB(labelCount,word2VecWithLableList,words):\n",
    "    \"\"\"\n",
    "    根据训练好的模型，预测输入向量的类型\n",
    "    输出为预测类别\n",
    "    \"\"\"\n",
    "    lableList = list(word2VecWithLableList.keys())\n",
    "    probaList = []\n",
    "    for lable in lableList:\n",
    "        proba = 0.0\n",
    "        word2VecList = word2VecWithLableList[lable]\n",
    "        for word in words:\n",
    "            if word in word2VecList:\n",
    "                proba -= log2(word2VecList[word])\n",
    "        lablePro = labelCount[lable] / np.sum(list(labelCount.values()))\n",
    "        probaList.append(proba - log2(lablePro))\n",
    "#         probaList.append(proba)\n",
    "#     print(probaList)\n",
    "    return lableList[np.argmax(probaList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d2210811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(train_data,train_label,val_data, val_label):\n",
    "    labelCount,word2VecWithLableList = word2VecWithLable(train_data,train_label)\n",
    "    acc = 0\n",
    "    for i in range(len(val_data)):\n",
    "#         print(classifyNB(labelCount,word2VecWithLableList,val_data[i]), val_label[i])\n",
    "        if classifyNB(labelCount,word2VecWithLableList,val_data[i]) == val_label[i]:\n",
    "            acc += 1\n",
    "    return round((acc / len(val_data) * 100), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "da8f43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_label, val_label = load_data_and_split('./SMSSpamCollection',0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f259bd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0897\n"
     ]
    }
   ],
   "source": [
    "print(getAccuracy(train_data,train_label,val_data, val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "48012fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[269.81544372625115, 204.77724296990453]\n",
      "ham\n",
      "ham\n"
     ]
    }
   ],
   "source": [
    "labelCount,word2VecWithLableList = word2VecWithLable(train_data,train_label)\n",
    "print(classifyNB(labelCount,word2VecWithLableList,val_data[0]))\n",
    "print(val_label[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
